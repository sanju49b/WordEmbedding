{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvkBDZkmg_2Y",
        "outputId": "46c6ceba-3511-4f27-cc9a-9094fd6d3995"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-02-10 15:41:48--  https://archive.org/download/google-news-vectors-negative-300.bin_202311/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving archive.org (archive.org)... 207.241.224.2\n",
            "Connecting to archive.org (archive.org)|207.241.224.2|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ia601203.us.archive.org/18/items/google-news-vectors-negative-300.bin_202311/GoogleNews-vectors-negative300.bin.gz [following]\n",
            "--2025-02-10 15:41:49--  https://ia601203.us.archive.org/18/items/google-news-vectors-negative-300.bin_202311/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving ia601203.us.archive.org (ia601203.us.archive.org)... 207.241.227.133\n",
            "Connecting to ia601203.us.archive.org (ia601203.us.archive.org)|207.241.227.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1647046227 (1.5G) [application/octet-stream]\n",
            "Saving to: ‘GoogleNews-vectors-negative300.bin.gz’\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   1.53G  2.78MB/s    in 9m 30s  \n",
            "\n",
            "2025-02-10 15:51:18 (2.76 MB/s) - ‘GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Slower but always guaranteed to work\n",
        "!wget -nc https://archive.org/download/google-news-vectors-negative-300.bin_202311/GoogleNews-vectors-negative300.bin.gz\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0TPn9pEiKHa"
      },
      "source": [
        " Training word embeddings from scratch, especially large-scale models like Word2Vec, GloVe, or transformer-based models (e.g., BERT, GPT), is extremely expensive and requires:\n",
        "\n",
        "Large datasets (e.g., billions of words from sources like Wikipedia, Common Crawl, or large corpora).\n",
        "High computational power (GPUs, TPUs).\n",
        "Extensive training time (weeks to months for large models).\n",
        "Significant expertise (hyperparameter tuning, optimization techniques, etc.).\n",
        "Why Use Pre-Trained Word Embeddings?\n",
        "Instead of training from scratch, we can use pre-trained word embeddings, which: ✅ Save time and computational cost\n",
        "✅ Provide high-quality representations\n",
        "✅ Work well for most NLP applications"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOORSyTchL1v"
      },
      "outputs": [],
      "source": [
        "#We are looking at the code of the neural embedding, in here we are typically download\n",
        "#Some pre trained word embedding to save the cost and effort\n",
        "#Because they require Large Datasets\n",
        "#We cannot really train models like transformers as these models tend up to cost million dollars\\\n",
        "#Without including the cost of expermentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1T1Qq5EEiWbg"
      },
      "outputs": [],
      "source": [
        "!gunzip GoogleNews-vectors-negative300.bin.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJ_CH7gHjGBS"
      },
      "outputs": [],
      "source": [
        "#This is a pre-trained Word2Vec model trained on Google News\n",
        "#(3 million words, 300-dimensional vectors)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vENlRz-rjF_i"
      },
      "outputs": [],
      "source": [
        "from gensim.models import KeyedVectors\n",
        "#this api containes necessary word emebeddings for the dataset we downloaded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlp0ydvdi6F4"
      },
      "outputs": [],
      "source": [
        "word_vectors = KeyedVectors.load_word2vec_format(\n",
        "  'GoogleNews-vectors-negative300.bin',\n",
        "  binary=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMf8l3h-kGoN"
      },
      "outputs": [],
      "source": [
        "def find_analogy(w1,w2,w3):\n",
        "  #w1-w2=?-w3\n",
        "  #king-man=? - woman\n",
        "  #?=king+woman-man\n",
        "  r=word_vectors.most_similar(positive=[w1,w3],negative=[w2])\n",
        "  print(\"%s-%s=%s-%s\" % (w1,w2,r[0][0],w3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oCigwoZmzjr",
        "outputId": "7f510392-2f7f-4321-9e62-65ac0086265d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "king-man=queen-woman\n"
          ]
        }
      ],
      "source": [
        "find_analogy('king','man','woman')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-R6tN93Vm6yQ",
        "outputId": "44743a04-c4a5-44be-cbc2-720d9343b9dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "france-paris=europe-england\n"
          ]
        }
      ],
      "source": [
        "find_analogy('france','paris','england')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nK35Z5OMoPk7",
        "outputId": "339cbe0d-1c0c-4941-cc3f-1764e69c8b79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "france-paris=italy-rome\n"
          ]
        }
      ],
      "source": [
        "find_analogy('france', 'paris', 'rome')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iz_Inbtao3xy",
        "outputId": "47f33c81-a887-45e9-890d-d7b6aa7ee92d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "france-french=england-english\n"
          ]
        }
      ],
      "source": [
        "find_analogy('france', 'french', 'english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYa5Ci8Lo7QL",
        "outputId": "21a190f9-994e-4a3c-e5a1-96f39204bf99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "japan-japanese=tibet-chinese\n"
          ]
        }
      ],
      "source": [
        "find_analogy('japan', 'japanese', 'chinese')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NY9Nkvqso9ts",
        "outputId": "8b3a7737-cecd-4ab0-8814-868b5a11d965"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "december-november=september-june\n"
          ]
        }
      ],
      "source": [
        "find_analogy('december', 'november', 'june')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JWK4CuppAas"
      },
      "outputs": [],
      "source": [
        "#given a word find the nearest words\n",
        "def nearest_neighbors(w):\n",
        "  r=word_vectors.most_similar(positive=[w])\n",
        "  print(\"neighbors of: %s\" % w)\n",
        "  for word,score in r:\n",
        "    print(\"\\t%s\"%word)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuHfz5pCp6AN",
        "outputId": "990f2abd-6879-4c6b-9db1-c4932d77047d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "neighbors of: king\n",
            "\tkings\n",
            "\tqueen\n",
            "\tmonarch\n",
            "\tcrown_prince\n",
            "\tprince\n",
            "\tsultan\n",
            "\truler\n",
            "\tprinces\n",
            "\tPrince_Paras\n",
            "\tthrone\n"
          ]
        }
      ],
      "source": [
        "nearest_neighbors('king')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W30ZTv2SqAhO",
        "outputId": "e9c665e1-a7cf-4b90-bd88-1bb57d18547f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "neighbors of: france\n",
            "\tspain\n",
            "\tfrench\n",
            "\tgermany\n",
            "\teurope\n",
            "\titaly\n",
            "\tengland\n",
            "\teuropean\n",
            "\tbelgium\n",
            "\tusa\n",
            "\tserbia\n"
          ]
        }
      ],
      "source": [
        "nearest_neighbors('france')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYPJKu0qqEJZ",
        "outputId": "1e0afef9-8a9b-4429-e8a1-b7649dac9cd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "neighbors of: einstein\n",
            "\tnikki\n",
            "\tlmfao\n",
            "\talbert\n",
            "\tarmstrong\n",
            "\tjoan\n",
            "\tbecky\n",
            "\tmcmahon\n",
            "\tconrad\n",
            "\tlori\n",
            "\thaley\n"
          ]
        }
      ],
      "source": [
        "nearest_neighbors('einstein')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uczBd9O1qGAE"
      },
      "outputs": [],
      "source": [
        "# Exercise: download pretrained GloVe vectors from\n",
        "# https://nlp.stanford.edu/projects/glove/\n",
        "#\n",
        "# Implement your own find_analogies() and nearest_neighbors()\n",
        "#\n",
        "# Hint: you do NOT have to go hunting around on Stackoverflow\n",
        "#       you do NOT have to copy and paste code from anywhere\n",
        "#       look at the file you downloaded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GnwzMuKqRjU",
        "outputId": "4cd07fd5-a467-4f92-d69a-334d94d42128"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'glove'...\n",
            "remote: Enumerating objects: 661, done.\u001b[K\n",
            "remote: Counting objects: 100% (69/69), done.\u001b[K\n",
            "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
            "remote: Total 661 (delta 37), reused 47 (delta 32), pack-reused 592 (from 1)\u001b[K\n",
            "Receiving objects: 100% (661/661), 248.05 KiB | 2.85 MiB/s, done.\n",
            "Resolving deltas: 100% (375/375), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/stanfordnlp/glove"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWbncOXBqRzf"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "import gensim.downloader as api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJjyfGTxxLzz",
        "outputId": "49efd9e4-febc-4e06-8873-fce599783a80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "[==================================================] 100.0% 376.1/376.1MB downloaded\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim  # Ensure Gensim is installed\n",
        "\n",
        "import gensim.downloader as api  # Import the downloader\n",
        "\n",
        "# Load the pretrained GloVe model (300D)\n",
        "glove_model = api.load(\"glove-wiki-gigaword-300\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkvdFzrTx045"
      },
      "outputs": [],
      "source": [
        "def nearest_neighbors(w, top_n=5):\n",
        "    \"\"\"Finds and prints the top N nearest neighbors of a given word.\"\"\"\n",
        "    try:\n",
        "        results = word_vectors.most_similar(positive=[w], topn=top_n)\n",
        "        print(f\"Neighbors of '{w}':\")\n",
        "        for word, score in results:\n",
        "            print(f\"\\t{word} ({score:.4f})\")\n",
        "    except KeyError:\n",
        "        print(f\"'{w}' is not in the vocabulary!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSKn-m4uzLPI",
        "outputId": "9fe9cfed-0b09-4e27-9b43-1d3aefc22772"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Neighbors of 'king':\n",
            "\tkings (0.7138)\n",
            "\tqueen (0.6511)\n",
            "\tmonarch (0.6413)\n",
            "\tcrown_prince (0.6204)\n",
            "\tprince (0.6160)\n"
          ]
        }
      ],
      "source": [
        "nearest_neighbors(\"king\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nzu6-59_zTnY",
        "outputId": "a103176f-87f8-492c-ebd2-1d3a01205f99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Neighbors of 'apple':\n",
            "\tapples (0.7204)\n",
            "\tpear (0.6451)\n",
            "\tfruit (0.6410)\n",
            "\tberry (0.6302)\n",
            "\tpears (0.6134)\n",
            "\tstrawberry (0.6058)\n",
            "\tpeach (0.6026)\n",
            "\tpotato (0.5961)\n",
            "\tgrape (0.5936)\n",
            "\tblueberry (0.5867)\n"
          ]
        }
      ],
      "source": [
        "nearest_neighbors(\"apple\", top_n=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mWnVUUB-zWHo",
        "outputId": "50d0713f-f3fa-45e9-da49-dd47a2422e43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "king - man = queen - woman\n",
            "france - paris = pakistan - india\n"
          ]
        }
      ],
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "# Load the pretrained GloVe model\n",
        "word_vectors = api.load(\"glove-wiki-gigaword-300\")\n",
        "\n",
        "def find_analogy(w1, w2, w3):\n",
        "    \"\"\"Finds and prints the word analogy of the form: w1 - w2 = ? - w3\"\"\"\n",
        "    try:\n",
        "        results = word_vectors.most_similar(positive=[w1, w3], negative=[w2])\n",
        "        print(f\"{w1} - {w2} = {results[0][0]} - {w3}\")\n",
        "    except KeyError:\n",
        "        print(f\"One of the words: '{w1}', '{w2}', or '{w3}' is not in the vocabulary!\")\n",
        "\n",
        "# Example usage\n",
        "find_analogy('king', 'man', 'woman')  # King - Man = ? - Woman\n",
        "find_analogy('france', 'paris', 'india')  # France - Paris = ? - India\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}